{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from utils import (get_data, display_results,\n",
    "                   get_label_encoder, get_train_dev_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lang</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GER</td>\n",
       "      <td>IThe importance and popularity of travelling ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TUR</td>\n",
       "      <td>It is an important decision , how to plan you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHI</td>\n",
       "      <td>Some people believe that young people can enj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEL</td>\n",
       "      <td>Travelling is usually considered as good recr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ARA</td>\n",
       "      <td>i agree that . Life is a person live period o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Lang                                               Text\n",
       "0  GER   IThe importance and popularity of travelling ...\n",
       "1  TUR   It is an important decision , how to plan you...\n",
       "2  CHI   Some people believe that young people can enj...\n",
       "3  TEL   Travelling is usually considered as good recr...\n",
       "4  ARA   i agree that . Life is a person live period o..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ARA', 'CHI', 'FRE', 'GER', 'HIN', 'ITA', 'JPN', 'KOR', 'OTH',\n",
       "       'SPA', 'TEL', 'TUR'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.append(df[\"Lang\"], \"OTH\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder, labels = get_label_encoder(np.unique(np.append(df[\"Lang\"], \"OTH\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ARA': 0,\n",
       " 'CHI': 1,\n",
       " 'FRE': 2,\n",
       " 'GER': 3,\n",
       " 'HIN': 4,\n",
       " 'ITA': 5,\n",
       " 'JPN': 6,\n",
       " 'KOR': 7,\n",
       " 'OTH': 8,\n",
       " 'SPA': 9,\n",
       " 'TEL': 10,\n",
       " 'TUR': 11}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train: index=[   1    3    4 ... 9895 9897 9898]\n",
      "  Test:  index=[   0    2   20 ... 9892 9896 9899]\n",
      "Fold 1:\n",
      "  Train: index=[   0    1    2 ... 9896 9898 9899]\n",
      "  Test:  index=[   4    7    9 ... 9887 9890 9897]\n",
      "Fold 2:\n",
      "  Train: index=[   0    2    3 ... 9896 9897 9899]\n",
      "  Test:  index=[   1   11   25 ... 9875 9884 9898]\n",
      "Fold 3:\n",
      "  Train: index=[   0    1    2 ... 9897 9898 9899]\n",
      "  Test:  index=[   8   13   14 ... 9882 9888 9893]\n",
      "Fold 4:\n",
      "  Train: index=[   0    1    2 ... 9897 9898 9899]\n",
      "  Test:  index=[   3    5    6 ... 9883 9894 9895]\n"
     ]
    }
   ],
   "source": [
    "X, y = df[\"Text\"], df[\"Lang\"]\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "splits = skf.split(X, y)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(splits):\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "    print(f\"  Test:  index={test_index}\")\n",
    "    train_idx = train_index\n",
    "    test_idx = test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_split(df, language):\n",
    "    lang = df[df[\"Lang\"]==language]\n",
    "\n",
    "    other = df[df[\"Lang\"]!=language]\n",
    "    other = other.sample(len(lang))\n",
    "    other[\"Lang\"] = \"OTH\"\n",
    "\n",
    "    df_concat = pd.concat([lang, other])\n",
    "    df_concat = df_concat.sample(frac=1, random_state=42)\n",
    "\n",
    "    X, y = df_concat[\"Text\"], df_concat[\"Lang\"]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(y_true, y_pred):\n",
    "    true = 0\n",
    "    false = 0\n",
    "    total_size = 0\n",
    "    one_size = 0\n",
    "    size_zero = 0\n",
    "    true_size_one = 0\n",
    "\n",
    "    different = []\n",
    "    total_different = 0\n",
    "    for i in range(len(y_true)):\n",
    "        if y_pred[i] not in different:\n",
    "            different.append(y_pred[i])\n",
    "            total_different += 1\n",
    "        if len(y_pred[i]) == 1:\n",
    "            if y_true[i] == y_pred[i][0]:\n",
    "                true_size_one += 1\n",
    "            one_size += 1\n",
    "        if len(y_pred[i]) == 0:\n",
    "            size_zero += 1\n",
    "        total_size += len(y_pred[i])\n",
    "        if y_true[i] in y_pred[i]:\n",
    "            true += 1\n",
    "        else:\n",
    "            false += 1\n",
    "    res = {\n",
    "        \"accuracy\": true/(false+true),\n",
    "        \"mean_size_tab\": total_size/len(y_true),\n",
    "        \"ratio_size_one\": one_size/len(y_true),\n",
    "        \"nb_different_tab\": total_different/len(y_true),\n",
    "        \"size_zero\": size_zero,\n",
    "        \"accuracy_size_one\": true_size_one/one_size\n",
    "    }\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(df):\n",
    "    array = np.append(df[\"Lang\"], \"OTH\")\n",
    "    label_encoder, labels = get_label_encoder(array)\n",
    "    train, test = df.loc[train_idx], df.loc[test_idx]\n",
    "\n",
    "    models = {}\n",
    "\n",
    "    # Train the models\n",
    "    for lang in df[\"Lang\"].unique():\n",
    "        clf = make_pipeline(\n",
    "            TfidfVectorizer(), \n",
    "            SGDClassifier()\n",
    "        )\n",
    "        X_train, y_train = get_df_split(train, lang)\n",
    "        X_dev, y_dev = get_df_split(test, lang)\n",
    "\n",
    "        y_train_labels = label_encoder.transform(y_train)\n",
    "        y_dev_labels = label_encoder.transform(y_dev)\n",
    "\n",
    "        clf.fit(X_train, y_train_labels)\n",
    "        \n",
    "        pred = clf.predict(X_dev)\n",
    "\n",
    "        models[lang] = {\"model\":clf, \"y_pred\":pred, \"y_true\":y_dev_labels}\n",
    "        print(f\"Accuracy for {lang}: {accuracy_score(y_dev_labels, pred)}\")\n",
    "    \n",
    "    results = {}\n",
    "    y_true = label_encoder.transform(test[\"Lang\"])\n",
    "    # Use the models\n",
    "    for model in models:\n",
    "        pred = models[model][\"model\"].predict(test[\"Text\"])\n",
    "        results[model] = {\"y_pred\":pred, \"y_true\":y_true}\n",
    "    \n",
    "    pred = []\n",
    "    for lang in results:\n",
    "        y_pred = results[lang][\"y_pred\"]\n",
    "        pred.append(y_pred)\n",
    "\n",
    "    real_pred = [[] for _ in range(len(pred[0]))]\n",
    "    for i in range(len(pred)):\n",
    "        for j in range(len(pred[i])):\n",
    "            if pred[i][j] != 8:\n",
    "                real_pred[j].append(pred[i][j])\n",
    "\n",
    "    \n",
    "\n",
    "    return models, results, get_accuracy(y_true, real_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for GER: 0.9222222222222223\n",
      "Accuracy for TUR: 0.8166666666666667\n",
      "Accuracy for CHI: 0.8527777777777777\n",
      "Accuracy for TEL: 0.9388888888888889\n",
      "Accuracy for ARA: 0.8222222222222222\n",
      "Accuracy for SPA: 0.8138888888888889\n",
      "Accuracy for HIN: 0.8305555555555556\n",
      "Accuracy for JPN: 0.8277777777777777\n",
      "Accuracy for KOR: 0.8555555555555555\n",
      "Accuracy for FRE: 0.8472222222222222\n",
      "Accuracy for ITA: 0.8722222222222222\n"
     ]
    }
   ],
   "source": [
    "models, results, acc = train_models(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8585858585858586,\n",
       " 'mean_size_tab': 2.3217171717171716,\n",
       " 'ratio_size_one': 0.1919191919191919,\n",
       " 'nb_different_tab': 0.16767676767676767,\n",
       " 'size_zero': 34,\n",
       " 'accuracy_size_one': 0.7842105263157895}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implémentation Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df.loc[train_idx], df.loc[test_idx]\n",
    "\n",
    "X_train, y_train = train[\"Text\"], train[\"Lang\"]\n",
    "X_test, y_test = test[\"Text\"], test[\"Lang\"]\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "\n",
    "\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "y_train = label_encoder.transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "base_lr = SGDClassifier()\n",
    "ovr = OneVsRestClassifier(base_lr)\n",
    "ovr.fit(X_train, y_train)\n",
    "Y_pred_ovr = ovr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7186868686868687"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, Y_pred_ovr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test JOUR-J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lang</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GER</td>\n",
       "      <td>I disagree with this statement because i thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GER</td>\n",
       "      <td>Yes , I do agree with the quoted statement . ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GER</td>\n",
       "      <td>In my opinion young people do not support the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GER</td>\n",
       "      <td>Since I am attending the final year of second...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GER</td>\n",
       "      <td>Since most of our neighbours are pretty old p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Lang                                               Text\n",
       "0  GER   I disagree with this statement because i thin...\n",
       "1  GER   Yes , I do agree with the quoted statement . ...\n",
       "2  GER   In my opinion young people do not support the...\n",
       "3  GER   Since I am attending the final year of second...\n",
       "4  GER   Since most of our neighbours are pretty old p..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = \"test.csv\"\n",
    "\n",
    "test = pd.read_csv(file_name)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"test.csv\"\n",
    "\n",
    "test = pd.read_csv(file_name)\n",
    "\n",
    "X_test = test[\"Text\"]\n",
    "\n",
    "\n",
    "df = get_data()\n",
    "\n",
    "X_train, y_train = df[\"Text\"], df[\"Lang\"]\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "y_train = label_encoder.transform(y_train)\n",
    "X_vect_test = vectorizer.transform(X_test)\n",
    "\n",
    "base_lr = SGDClassifier()\n",
    "ovr = OneVsRestClassifier(base_lr)\n",
    "ovr.fit(X_train, y_train)\n",
    "Y_pred_ovr = ovr.predict(X_vect_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "        3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "        3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "        3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "        3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "        3,  3,  3,  3,  3, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
       "        9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
       "        9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
       "        9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
       "        9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
       "        9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  4,  4,  4,  4,\n",
       "        4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
       "        4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
       "        4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
       "        4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
       "        4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
       "        4,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
       "        7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
       "        7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
       "        7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
       "        7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
       "        7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "        5,  5,  5,  5])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_ovr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".lang_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
